{
  "traces": [],
  "train": [],
  "demos": [],
  "signature": {
    "instructions": "You will be given a clinical handover transcript (dialogue with speaker tags like “[OUTGOING_NURSE]: …”). Your job is to extract SBAR “quotes” as EXACT substrings from the transcript and return them in reading order as a JSON-like list:\n[\n  {\"label\": \"SITUATION\"|\"BACKGROUND\"|\"ASSESSMENT\"|\"RECOMMENDATION\", \"quote\": \"<verbatim substring>\"}\n]\n\nThis dataset is evaluated with character-span overlap (IoU). Small boundary differences (extra period, missing leading comma, missing trailing clause) can cause misses. Optimize for matching the dataset’s preferred boundaries, not for “ideal” SBAR summarization.\n\nHARD RULES (must follow)\n1) Verbatim only\n- Copy quotes EXACTLY as they appear (same punctuation, symbols like “SpO?”, capitalization, curly quotes, dashes, commas).\n- Do NOT paraphrase, normalize, or correct.\n- Do NOT add/remove words.\n- Do NOT include speaker tags unless the gold span clearly includes them (assume usually NOT).\n\n2) Contiguous spans only\n- Each quote must be a single contiguous substring from the transcript.\n- Do NOT stitch non-adjacent parts together.\n\n3) One label per quote\n- Each quote has exactly one SBAR label.\n\n4) Output only SBAR-relevant content\n- Omit greetings/thanks/introductions unless they contain SBAR content the dataset tends to keep (see “dataset quirks”).\n\nDATASET QUIRKS YOU MUST MODEL (learned from examples/feedback)\nA) Gold spans often include punctuation fragments and partial clauses\n- Gold may start mid-sentence, including a leading comma or period, e.g. “, are you managing okay with eating, drinking, and getting around?” or “. He’s had a full septic workup; results are pending”.\n- Gold may end before an intuitive endpoint, e.g. “He’s febrile—38.6—and we’ve” (stop exactly there if that’s the SBAR-bearing chunk).\n=> Therefore: do NOT “clean up” boundaries. If SBAR content begins after a comma/period in the transcript, include that punctuation if it is immediately attached in the text.\n\nB) Prefer the dataset’s chunking over “tightest possible”\n- Although “tight boundaries” are generally good, gold sometimes groups multiple clinically related sentences into one span (e.g., Situation can include the fall + fracture + immobilised + ortho reviewed as one continuous span).\n- Conversely, gold sometimes extracts only a tiny tail phrase (e.g., Background gold might be only “for the same reason”).\n=> Strategy: extract at natural transcript boundaries, but be willing to (i) keep multi-sentence spans together when they form one continuous “event/status” block, and (ii) also extract very short sub-clauses when they are clearly isolated in the transcript.\n\nC) Questions are sometimes gold-labeled (do not ignore them)\n- Some clinician questions are treated as SBAR content in this dataset and should be extracted verbatim, especially assessment-context prompts (e.g., “Any allergies documented?”) and functional assessment questions (e.g., “, are you managing okay with eating, drinking, and getting around?”).\n- Keep the question exactly as written, including leading punctuation if present.\n\nD) Patient statements can be ASSESSMENT\n- Patient-reported symptoms/functional status are often gold ASSESSMENT (e.g., “A bit sore, but okay. Just tired.”; “I can manage with my right hand. I just need help getting to the bathroom”).\n- Even bracketed actions can be ASSESSMENT if present as text (e.g., “: (weak hand squeeze)”).\n\nE) Recommendations often include “I’ll…” / “we’ll…” and can be long multi-action spans\n- Extract explicit next steps, including nursing intentions and monitoring plans.\n- Gold may include a long continuous recommendation sentence(s) as one span (e.g., the entire “I’ll check… I’ll also keep an eye…” block).\n- Also capture smaller recommendation items when clearly standalone (e.g., “OT and physio have been referred for tomorrow.”; “awaiting psych and medication review”).\n\nLABELING GUIDANCE (match dataset tendencies)\nSITUATION (why here / what’s happening now / disposition)\n- Reason for admission/presentation (“He’s just arrived with depression”).\n- Current status blocks about the acute issue and immediate status updates that are framed as situation (dataset may treat “septic workup pending” / “blood cultures… awaiting results” as SITUATION).\n- If a continuous block describes presentation + immediate diagnosis/initial management, consider keeping it as one SITUATION span if contiguous (even across sentences).\n\nBACKGROUND (stable context/history OR certain prompts)\n- Past history/comorbidities, allergies, baseline context.\n- This dataset may label some clinician prompts as BACKGROUND (e.g., “Any allergies documented?”).\n- Code status may appear as BACKGROUND in gold (e.g., “He’s for full resuscitation.”).\n\nASSESSMENT (broad: current state/findings/therapies/needs; includes questions & patient responses)\n- Symptoms, pain, functional status, vitals, obs stability statements IF they match transcript wording.\n- Current therapies running (antibiotics running, fluids rate), NBM status, lines/tubes, results as “findings”.\n- Include assessment questions when they function as assessment content in the exchange.\n- Be careful: don’t invent common phrases (“vitals stable”) if not part of the gold-preferred snippet; prefer extracting the exact SBAR-relevant clause that appears in the transcript (e.g., gold used “No acute medical issues flagged,” rather than “Observations are stable.”).\n\nRECOMMENDATION (next steps / monitoring / escalation / referrals / awaiting)\n- “awaiting … review” type phrases are often RECOMMENDATION (e.g., “awaiting psych and medication review”).\n- Referrals planned (“OT and physio have been referred for tomorrow.”).\n- Receiving nurse plans (“I’ll make sure your obs are done as scheduled and keep you updated …”).\n- Medical plan statements (“Dr. Geller will come later to review and advise”) are RECOMMENDATION when framed as what will happen next.\n\nEXTRACTION METHOD (to improve IoU)\n1) Traverse transcript in order and identify SBAR-bearing regions.\n2) For each region, choose spans that:\n   - are contiguous exact substrings,\n   - match the transcript’s own punctuation/clause boundaries,\n   - include leading punctuation if the SBAR content starts right after it,\n   - include trailing partial clauses if the transcript attaches them in the same SBAR-bearing segment (do not “finish the sentence” yourself).\n3) When a single continuous block contains multiple SBAR items:\n   - If the dataset likely keeps it together (common for initial situation blocks; common for long “I’ll … I’ll also …” recommendations), keep it together.\n   - If the transcript provides a clear split and the items are different types (e.g., allergy + past history; meds + pain score; separate referrals), split accordingly.\n4) Do not output non-SBAR chit-chat unless it matches the “questions are gold” rule above.\n\nOUTPUT\n- Return only the list of {\"label\",\"quote\"} objects, in reading order.\n- No extra commentary.",
    "fields": [
      {
        "prefix": "Text:",
        "description": "${text}"
      },
      {
        "prefix": "Pred Spans:",
        "description": "${pred_spans}"
      }
    ]
  },
  "lm": null,
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.1.3",
      "cloudpickle": "3.1"
    }
  }
}
