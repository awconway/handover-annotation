{
  "traces": [],
  "train": [],
  "demos": [],
  "signature": {
    "instructions": "text\nTask\nYou will be given a clinical bedside handover transcript as plain text with speaker tags (e.g., [OUTGOING_NURSE]:, [INCOMING_NURSE]:, [DOCTOR]:, [PATIENT]:). Your job is to extract ONLY the exact contiguous substrings that this specific dataset is likely to annotate with label UNCERTAIN.\n\nOutput (STRICT)\nReturn ONLY a JSON-like list of dicts (no prose, no extra keys):\n  {'label': 'UNCERTAIN', 'quote': '<verbatim contiguous substring from transcript>'}\nIf none, return [].\n\nHard constraints\n- The quote MUST be copied verbatim from the transcript (exact casing, punctuation, spacing).\n- Each quote must be a single contiguous substring (no stitching).\n- Output separate items for separate cues; do not merge non-contiguous text.\n- Precision > recall (false positives are heavily penalized). When unsure, skip.\n- BUT: when you DO extract, match boundaries “gold-style” tightly (gold sometimes includes a short lead-in phrase/sentence, not only the cue word).\n\nWhat this dataset actually labels as UNCERTAIN (important, learned from feedback)\nThis dataset is NOT labeling “logical uncertainty” in general. It tends to label a narrow set of handover-style qualitative/hedged statements.\n\nHIGH-YIELD (prioritize these)\n1) Clinician qualitative stability/normality summaries\nThese are frequently labeled UNCERTAIN even though they sound certain:\n- “He’s been stable overnight”\n- “Otherwise, he’s stable.”\n- “observations … stable/normal”\n- “vitals stable”\nBoundary: usually the short clause/sentence containing “stable/normal”, sometimes with a small lead-in if it reads as one uncertainty statement.\n\n2) “No changes / no concerns” overnight summaries (clinician)\n- “There have been no changes overnight.”\n- “No concerns overnight.”\nOften labeled UNCERTAIN.\nBoundary behavior: if written as two contiguous sentences like:\n  “There have been No changes overnight. All observations have remained stable.”\ngold may annotate the combined two-sentence block. If that exact combined block appears contiguously, prefer extracting the whole combined block as a single span.\n\n3) Hopeful/hedged discharge or timing phrased with “Hopefully …”\n- e.g., “Hopefully tomorrow …”\nExtract the minimal “Hopefully …” clause (don’t include adjacent definite plans unless tightly coupled in the same clause).\n\nCRITICAL ADDITION (from examples): explicit epistemic/hedging language is often labeled UNCERTAIN\nExample 1 shows the gold contains MANY uncertainty spans beyond “stable/hopefully”, including common clinician hedges such as:\n- “what looks like …”\n- “fairly convincing”\n- “tentatively …”\n- “might …”\n- “depending on …”\n- “a bit …”\n- “I believe …”\n- “seems to …”\n- “look like they’re trending …”\n- “isn’t in yet” (missing/unknown result)\n- “I think …”\n- “need to double-check …”\n- “possible …”\n- “not sure if … yet”\n- “as far as documented”\n- “I’ll have to check if …”\n- “mentioned … but I didn’t see … yet”\n- “planning to …”\nThese should be extracted when they are clearly functioning as uncertainty/hedging (not just narrative), and when you can copy an exact contiguous clause.\n\nLOW-YIELD / AVOID (common false positives)\nA) “pending/awaiting results/review” admin phrases are NOT reliably gold by themselves.\nDo NOT automatically extract “pending”, “awaiting review”, “to be reviewed”, “not seen yet” unless it is embedded in a stronger explicit epistemic hedge (e.g., “I’m not sure if it’s been booked yet”, “the last result isn’t in yet”).\n\nB) Patient self-reports that are vague are often NOT labeled\nAvoid spans like patient: “I’m okay”, “about the same”, worries/preferences, etc.\n\nC) “Unknown origin / under investigation” without explicit epistemic cues\nDo not label unless explicit “unclear / not sure / I don’t know / can’t rule out / query” etc.\n\nD) Conditional requests/preferences that aren’t clinician uncertainty\nAvoid “if it’s safe”, “if the team agrees” unless clearly clinician hedging in the same clause (esp. “Hopefully …”).\n\nBoundary / IoU optimization rules\n- Extract the smallest gold-like unit that contains the uncertainty statement.\n- Do not include adjacent numeric vitals/oxygen/med doses/timestamps/procedure details unless they are inseparable from the hedged clause.\n- Include punctuation only if it is part of the exact span you are copying.\n- If a hedge attaches to a dependent clause, include enough surrounding words to make it a natural contiguous “uncertainty unit” (e.g., “I’m not sure if it’s been booked yet.” rather than only “not sure”).\n- When there are multiple hedges in one sentence, prefer splitting into multiple spans only if they are clearly separable as contiguous substrings without dragging lots of extra factual content; otherwise choose the clearest hedge clause.\n\nPractical decision policy\n1) Scan for explicit hedge markers: “I think”, “I believe”, “seems”, “looks like”, “might”, “may”, “tentatively”, “probably”, “fairly”, “a bit”, “depending on”, “unsure/not sure”, “need to check/double-check”, “as far as (I know)/(documented)”, “I’ll have to check”, “didn’t see … yet”, “isn’t in yet”.\n2) Also scan for clinician shift-summary qualitative phrases: “no changes overnight”, “no concerns”, “(observations/vitals) stable/normal”, “otherwise stable”.\n3) Also scan for “Hopefully …” timing/discharge hedges.\n4) Only output spans you are confident the dataset marks; output fewer rather than more.\n\nReturn only the JSON-like list of UNCERTAIN quotes.",
    "fields": [
      {
        "prefix": "Text:",
        "description": "${text}"
      },
      {
        "prefix": "Pred Spans:",
        "description": "${pred_spans}"
      }
    ]
  },
  "lm": null,
  "metadata": {
    "dependency_versions": {
      "python": "3.12",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
