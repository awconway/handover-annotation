#!/bin/bash -l
#PBS -N medgemma27b_baseline_consensus
#PBS -l select=1:ncpus=8:mem=64GB:ngpus=1:gpu_model=A100:gpu_sliced=False
#PBS -l walltime=04:00:00
#PBS -m abe
#PBS -j oe

set -euo pipefail

cd "$PBS_O_WORKDIR" || exit 1
export PATH="$HOME/.local/bin:$HOME/bin:$PATH"

# Persistent model cache on HOME (Lustre-backed on cluster)
export OLLAMA_MODELS="${OLLAMA_MODELS:-$HOME/.ollama/models}"

MODEL_IMAGE="alibayram/medgemma:27b"
MODEL_NAME="${MODEL_NAME:-ollama_medgemma_27b}"
DATA_FILE="${DATA_FILE:-./annotated_data/db_20260129_tokenised_consensus.jsonl}"
ANNOTATOR_ID="${ANNOTATOR_ID:-}"
USE_ALL="${USE_ALL:-0}"          # 1 => evaluate on all matching examples
RUN_CHECKLIST="${RUN_CHECKLIST:-1}"
RUN_SBAR="${RUN_SBAR:-1}"

STAMP="$(date +%Y%m%d_%H%M%S)"
OUT_DIR="${OUT_DIR:-./cluster_runs/medgemma27b_baseline_consensus_${STAMP}}"
mkdir -p "$OUT_DIR"/evals "$OUT_DIR"/logs
exec > >(tee -a "$OUT_DIR/logs/job.log") 2>&1

echo "Node: $(hostname)"
echo "Working directory: $PWD"
echo "Output directory: $OUT_DIR"
echo "GPU info:"
nvidia-smi

PYTHON_MODULE="${PYTHON_MODULE:-Python/3.12.3}"
PYTHON_MODULE_CANDIDATES="${PYTHON_MODULE_CANDIDATES:-}"
PYTHON_MIN_MAJOR="${PYTHON_MIN_MAJOR:-3}"
PYTHON_MIN_MINOR="${PYTHON_MIN_MINOR:-10}"
PYTHON_DEBUG_MODULE_LOAD="${PYTHON_DEBUG_MODULE_LOAD:-0}"
VENV_DIR="${VENV_DIR:-$PBS_O_WORKDIR/.venv_cluster_py312}"

if ! command -v module >/dev/null 2>&1; then
  echo "Environment modules are required but 'module' command is not available."
  exit 1
fi

if [ -z "$PYTHON_MODULE_CANDIDATES" ]; then
  DISCOVERED_PYTHON_MODULES="$(
    module --ignore_cache -t spider Python 2>&1 | awk '/^Python\// {print $1}' | tr '\n' ' '
  )"
  if [ -n "$DISCOVERED_PYTHON_MODULES" ]; then
    PYTHON_MODULE_CANDIDATES="$PYTHON_MODULE $DISCOVERED_PYTHON_MODULES"
  else
    PYTHON_MODULE_CANDIDATES="$PYTHON_MODULE"
  fi
fi
PYTHON_MODULE_CANDIDATES="$(
  printf '%s\n' $PYTHON_MODULE_CANDIDATES | awk 'NF && !seen[$0]++' | tr '\n' ' '
)"
echo "Python module candidates: $PYTHON_MODULE_CANDIDATES"

python_is_usable() {
  command -v python3 >/dev/null 2>&1 || return 1
  python3 -c "import sys; raise SystemExit(0 if sys.version_info >= (${PYTHON_MIN_MAJOR}, ${PYTHON_MIN_MINOR}) else 1)" >/dev/null 2>&1
}

extract_spider_chains() {
  local mod="$1"
  module --ignore_cache spider "$mod" 2>&1 | awk '
    /You will need to load all module\(s\) on any one of the lines below before the/ {capture=1; started=0; next}
    capture {
      if ($0 ~ /^[[:space:]]*$/) {
        if (started) next
        next
      }
      if ($0 ~ /^[[:space:]]+[[:alnum:]_.+-]+\/[[:alnum:]_.+-]+/) {
        line=$0
        gsub(/^[[:space:]]+/, "", line)
        gsub(/[[:space:]]+/, " ", line)
        print line
        started=1
        next
      }
      if (started && $0 !~ /^[[:space:]]/) exit
    }'
}

SELECTED_PYTHON_MODULE=""
SELECTED_PYTHON_CHAIN=""

try_python_module() {
  local mod="$1"
  local chain="$2"

  module purge >/dev/null 2>&1 || true

  if [ -n "$chain" ]; then
    local dep
    for dep in $chain; do
      if [ "$PYTHON_DEBUG_MODULE_LOAD" = "1" ]; then
        module load "$dep" || return 1
      else
        module load "$dep" >/dev/null 2>&1 || return 1
      fi
    done
  fi

  if [ "$PYTHON_DEBUG_MODULE_LOAD" = "1" ]; then
    module load "$mod" || return 1
  else
    module load "$mod" >/dev/null 2>&1 || return 1
  fi

  python_is_usable
  local rc=$?
  if [ "$rc" -eq 0 ]; then
    SELECTED_PYTHON_MODULE="$mod"
    SELECTED_PYTHON_CHAIN="$chain"
    return 0
  fi

  if [ "$rc" -eq 132 ]; then
    echo "  python3 crashed with illegal instruction for $mod ${chain:+(chain: $chain)}"
  fi
  return 2
}

ATTEMPT_INDEX=0
for mod in $PYTHON_MODULE_CANDIDATES; do
  ATTEMPT_INDEX=$((ATTEMPT_INDEX + 1))
  echo "Trying Python module [$ATTEMPT_INDEX]: $mod"

  if try_python_module "$mod" ""; then
    break
  fi

  while IFS= read -r chain; do
    [ -n "$chain" ] || continue
    echo "  trying prerequisite chain: $chain"
    if try_python_module "$mod" "$chain"; then
      break 2
    fi
  done < <(extract_spider_chains "$mod" | awk 'NF && !seen[$0]++')
done

if [ -z "$SELECTED_PYTHON_MODULE" ]; then
  echo "Could not load a runnable python3 >=${PYTHON_MIN_MAJOR}.${PYTHON_MIN_MINOR} on this node."
  echo "Tried PYTHON_MODULE_CANDIDATES: $PYTHON_MODULE_CANDIDATES"
  echo "Tip: set PYTHON_DEBUG_MODULE_LOAD=1 to show full module load errors."
  exit 1
fi

echo "Using Python module: $SELECTED_PYTHON_MODULE"
if [ -n "$SELECTED_PYTHON_CHAIN" ]; then
  echo "Using prerequisite chain: $SELECTED_PYTHON_CHAIN"
fi

if [ ! -x "$VENV_DIR/bin/python3" ] && [ ! -x "$VENV_DIR/bin/python" ]; then
  python3 -m venv "$VENV_DIR"
fi

PYTHON_BIN="$VENV_DIR/bin/python3"
if [ ! -x "$PYTHON_BIN" ]; then
  PYTHON_BIN="$VENV_DIR/bin/python"
fi
if ! "$PYTHON_BIN" -c "import sys; raise SystemExit(0 if sys.version_info >= (3, 10) else 1)" >/dev/null 2>&1; then
  echo "Existing venv is not runnable or is <3.10; recreating $VENV_DIR"
  python3 -m venv --clear "$VENV_DIR"
  PYTHON_BIN="$VENV_DIR/bin/python3"
  "$PYTHON_BIN" -c "import sys; raise SystemExit(0 if sys.version_info >= (3, 10) else 1)" >/dev/null
fi

DEPS_STAMP="$VENV_DIR/.handover_deps_v4"
if [ ! -f "$DEPS_STAMP" ]; then
  "$PYTHON_BIN" -m pip install --upgrade pip setuptools wheel
  "$PYTHON_BIN" -m pip install \
    "dspy-ai>=3.0.4" \
    "numpy>=2.3.5" \
    "rapidfuzz>=3.14.3" \
    "spacy>=3.8.11" \
    "thinc>=8.3.10" \
    "srsly>=2.5.1"
  touch "$DEPS_STAMP"
fi

export PYTHONPATH="$PWD/src${PYTHONPATH:+:$PYTHONPATH}"
PY_RUNNER=("$PYTHON_BIN")
if ! command -v ollama >/dev/null 2>&1; then
  echo "ollama is not available on PATH."
  exit 1
fi

# Pick a random free local port for this job's Ollama daemon.
while :; do
  PORT=$((11434 + RANDOM % 5000))
  if ! nc -z 127.0.0.1 "$PORT" 2>/dev/null; then
    break
  fi
done

export OLLAMA_HOST="127.0.0.1:${PORT}"
export OLLAMA_API_BASE="http://${OLLAMA_HOST}"
echo "Using OLLAMA_HOST=${OLLAMA_HOST}"
echo "Using OLLAMA_API_BASE=${OLLAMA_API_BASE}"

ollama serve >/dev/null 2>&1 &
OLLAMA_PID=$!
trap 'kill "$OLLAMA_PID" 2>/dev/null || true' EXIT

for i in {1..90}; do
  if curl -fs "http://${OLLAMA_HOST}/api/tags" >/dev/null; then
    break
  fi
  sleep 1
  if [ "$i" -eq 90 ]; then
    echo "Ollama did not start within 90 seconds."
    exit 1
  fi
done

if ! ollama show "$MODEL_IMAGE" >/dev/null 2>&1; then
  echo "Pulling ${MODEL_IMAGE}..."
  ollama pull "$MODEL_IMAGE"
else
  echo "Model ${MODEL_IMAGE} already available in local cache."
fi

echo "Available models:"
ollama list

COMMON_ARGS=(--data-file "$DATA_FILE" --model-name "$MODEL_NAME")
if [ -n "$ANNOTATOR_ID" ]; then
  COMMON_ARGS+=(--annotator-id "$ANNOTATOR_ID")
fi
EVAL_EXTRA_ARGS=()
if [ "$USE_ALL" = "1" ]; then
  EVAL_EXTRA_ARGS+=(--use-all)
fi

echo "Run configuration:"
echo "  DATA_FILE=$DATA_FILE"
echo "  RUN_CHECKLIST=$RUN_CHECKLIST"
echo "  RUN_SBAR=$RUN_SBAR"
echo "  ANNOTATOR_ID=${ANNOTATOR_ID:-<all>}"
echo "  USE_ALL=$USE_ALL"
echo "  Mode=baseline-eval-only"

if [ "$RUN_CHECKLIST" = "1" ]; then
  CHECKLIST_EVAL_FILE="$OUT_DIR/evals/eval_baseline_checklist_${MODEL_NAME}_consensus.jsonl"

  echo "=== CHECKLIST BASELINE EVAL ==="
  "${PY_RUNNER[@]}" run_eval_checklist.py \
    "${COMMON_ARGS[@]}" \
    --baseline \
    --eval-results-file "$CHECKLIST_EVAL_FILE" \
    "${EVAL_EXTRA_ARGS[@]}"
fi

if [ "$RUN_SBAR" = "1" ]; then
  SBAR_EVAL_FILE="$OUT_DIR/evals/eval_baseline_sbar_${MODEL_NAME}_consensus.jsonl"

  echo "=== SBAR BASELINE EVAL ==="
  "${PY_RUNNER[@]}" run_eval_sbar_span.py \
    "${COMMON_ARGS[@]}" \
    --baseline \
    --eval-results-file "$SBAR_EVAL_FILE" \
    "${EVAL_EXTRA_ARGS[@]}"
fi

echo "Consensus baseline evaluations completed."
echo "Artifacts:"
echo "  Evals: $OUT_DIR/evals"
echo "  Logs:  $OUT_DIR/logs/job.log"
