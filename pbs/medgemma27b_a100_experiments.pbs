#!/bin/bash -l
#PBS -N medgemma27b_experiments
#PBS -l select=1:ncpus=8:mem=64GB:ngpus=1:gpu_id=A100:gpu_sliced=False
#PBS -l walltime=08:00:00
#PBS -m abe
#PBS -j oe

set -euo pipefail

cd "$PBS_O_WORKDIR" || exit 1
export PATH="$HOME/.local/bin:$HOME/bin:$PATH"

# Persistent model cache on HOME (Lustre-backed on cluster)
export OLLAMA_MODELS="${OLLAMA_MODELS:-$HOME/.ollama/models}"

MODEL_IMAGE="alibayram/medgemma:27b"
MODEL_NAME="${MODEL_NAME:-ollama_medgemma_27b}"
DATA_FILE="${DATA_FILE:-./annotated_data/db_20260129_tokenised.jsonl}"
CHECKLIST_OPTIMISER="${CHECKLIST_OPTIMISER:-gepa_light_checklist}"
SBAR_OPTIMISER="${SBAR_OPTIMISER:-gepa_light_span}"
UNCERTAIN_OPTIMISER="${UNCERTAIN_OPTIMISER:-gepa_light_span}"
ANNOTATOR_ID="${ANNOTATOR_ID:-}"
USE_ALL="${USE_ALL:-0}"          # 1 => evaluate on all matching examples
RUN_TRAIN="${RUN_TRAIN:-1}"      # 1 => train then eval, 0 => baseline eval only
RUN_CHECKLIST="${RUN_CHECKLIST:-1}"
RUN_SBAR="${RUN_SBAR:-1}"
RUN_UNCERTAIN="${RUN_UNCERTAIN:-0}"
UNCERTAIN_SIGNATURE_MODE="${UNCERTAIN_SIGNATURE_MODE:-default}"
UNCERTAIN_ANNOTATOR_ID="${UNCERTAIN_ANNOTATOR_ID:-handover_db-user2}"
UNCERTAIN_EVAL_SPLIT="${UNCERTAIN_EVAL_SPLIT:-train}"
EVAL_MAX_RETRIES="${EVAL_MAX_RETRIES:-5}"
EVAL_RETRY_DELAY_SECONDS="${EVAL_RETRY_DELAY_SECONDS:-1.5}"
REFLECTION_MODEL="openai/gpt-5.2"
GPU_MONITOR_ENABLED="${GPU_MONITOR_ENABLED:-1}"
GPU_MONITOR_INTERVAL_SECONDS="${GPU_MONITOR_INTERVAL_SECONDS:-120}"

DATA_TAG="$(basename "$DATA_FILE")"
DATA_TAG="${DATA_TAG%.*}"
ANNOTATOR_TAG="${ANNOTATOR_ID:-all}"
UNCERTAIN_ANNOTATOR_TAG="$(printf '%s' "${UNCERTAIN_ANNOTATOR_ID:-$ANNOTATOR_TAG}" | tr -c '[:alnum:]_.-' '_')"
RUN_ID_DEFAULT="$(printf '%s' "medgemma27b_${MODEL_NAME}_${CHECKLIST_OPTIMISER}_${SBAR_OPTIMISER}_${UNCERTAIN_OPTIMISER}_${DATA_TAG}_${ANNOTATOR_TAG}_train${RUN_TRAIN}_check${RUN_CHECKLIST}_sbar${RUN_SBAR}_uncertain${RUN_UNCERTAIN}_uncsig${UNCERTAIN_SIGNATURE_MODE}_unannot${UNCERTAIN_ANNOTATOR_TAG}_unsplit${UNCERTAIN_EVAL_SPLIT}_all${USE_ALL}" | tr -c '[:alnum:]_.-' '_')"
RUN_ID="${RUN_ID:-$RUN_ID_DEFAULT}"
OUT_DIR="${OUT_DIR:-./cluster_runs/${RUN_ID}}"
mkdir -p "$OUT_DIR"/compiled_programs "$OUT_DIR"/evals "$OUT_DIR"/logs "$OUT_DIR"/gepa
exec > >(tee -a "$OUT_DIR/logs/job.log") 2>&1

OLLAMA_PID=""
GPU_MONITOR_PID=""
cleanup() {
  if [ -n "${GPU_MONITOR_PID:-}" ]; then
    kill "$GPU_MONITOR_PID" 2>/dev/null || true
  fi
  if [ -n "${OLLAMA_PID:-}" ]; then
    kill "$OLLAMA_PID" 2>/dev/null || true
  fi
}
trap cleanup EXIT

echo "Node: $(hostname)"
echo "Working directory: $PWD"
echo "Run ID: $RUN_ID"
echo "Output directory: $OUT_DIR"
echo "GPU info:"
nvidia-smi

VENV_DIR="${VENV_DIR:-$PBS_O_WORKDIR/.venv_cluster_gpu}"
PYTHON_MIN_MAJOR="${PYTHON_MIN_MAJOR:-3}"
PYTHON_MIN_MINOR="${PYTHON_MIN_MINOR:-11}"
PYTHON_BIN="$VENV_DIR/bin/python3"
if [ ! -x "$PYTHON_BIN" ]; then
  PYTHON_BIN="$VENV_DIR/bin/python"
fi

if [ ! -x "$PYTHON_BIN" ]; then
  echo "Expected virtual environment was not found at: $VENV_DIR"
  echo "Create it first with uv (example):"
  echo "  uv python install 3.11"
  echo "  uv venv --python 3.11 $VENV_DIR"
  exit 1
fi

if ! "$PYTHON_BIN" -c "import sys; raise SystemExit(0 if sys.version_info >= (${PYTHON_MIN_MAJOR}, ${PYTHON_MIN_MINOR}) else 1)" >/dev/null 2>&1; then
  echo "Venv interpreter is not runnable at >=${PYTHON_MIN_MAJOR}.${PYTHON_MIN_MINOR}: $PYTHON_BIN"
  "$PYTHON_BIN" -V || true
  exit 1
fi

echo "Using venv interpreter: $PYTHON_BIN"

DEPS_STAMP="$VENV_DIR/.handover_deps_v4"
if [ ! -f "$DEPS_STAMP" ]; then
  "$PYTHON_BIN" -m pip install --upgrade pip setuptools wheel
  "$PYTHON_BIN" -m pip install \
    "dspy-ai>=3.0.4" \
    "numpy>=2.3.5" \
    "rapidfuzz>=3.14.3" \
    "spacy>=3.8.11" \
    "thinc>=8.3.10" \
    "srsly>=2.5.1"
  touch "$DEPS_STAMP"
fi

export PYTHONPATH="$PWD/src${PYTHONPATH:+:$PYTHONPATH}"
PY_RUNNER=("$PYTHON_BIN")
if ! command -v ollama >/dev/null 2>&1; then
  echo "ollama is not available on PATH."
  exit 1
fi

GPU_UTIL_FILE="$OUT_DIR/logs/gpu_util.csv"
if [ "$GPU_MONITOR_ENABLED" = "1" ]; then
  if command -v nvidia-smi >/dev/null 2>&1; then
    {
      echo "timestamp,index,name,utilization_gpu_pct,utilization_mem_pct,memory_used_mib,memory_total_mib,temperature_c,power_draw_w"
      while :; do
        nvidia-smi \
          --query-gpu=timestamp,index,name,utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu,power.draw \
          --format=csv,noheader,nounits || true
        sleep "$GPU_MONITOR_INTERVAL_SECONDS"
      done
    } >> "$GPU_UTIL_FILE" &
    GPU_MONITOR_PID=$!
    echo "GPU monitoring enabled: ${GPU_UTIL_FILE} (interval=${GPU_MONITOR_INTERVAL_SECONDS}s)"
  else
    echo "GPU monitoring requested but nvidia-smi is unavailable; skipping."
  fi
fi

# Pick a random free local port for this job's Ollama daemon.
while :; do
  PORT=$((11434 + RANDOM % 5000))
  if ! nc -z 127.0.0.1 "$PORT" 2>/dev/null; then
    break
  fi
done

export OLLAMA_HOST="127.0.0.1:${PORT}"
export OLLAMA_API_BASE="http://${OLLAMA_HOST}"
export UNCERTAIN_SIGNATURE_MODE
echo "Using OLLAMA_HOST=${OLLAMA_HOST}"
echo "Using OLLAMA_API_BASE=${OLLAMA_API_BASE}"

ollama serve >/dev/null 2>&1 &
OLLAMA_PID=$!

for i in {1..90}; do
  if curl -fs "http://${OLLAMA_HOST}/api/tags" >/dev/null; then
    break
  fi
  sleep 1
  if [ "$i" -eq 90 ]; then
    echo "Ollama did not start within 90 seconds."
    exit 1
  fi
done

if ! ollama show "$MODEL_IMAGE" >/dev/null 2>&1; then
  echo "Pulling ${MODEL_IMAGE}..."
  ollama pull "$MODEL_IMAGE"
else
  echo "Model ${MODEL_IMAGE} already available in local cache."
fi

echo "Available models:"
ollama list

COMMON_ARGS=(--data-file "$DATA_FILE" --model-name "$MODEL_NAME")
if [ -n "$ANNOTATOR_ID" ]; then
  COMMON_ARGS+=(--annotator-id "$ANNOTATOR_ID")
fi
EVAL_EXTRA_ARGS=()
if [ "$USE_ALL" = "1" ]; then
  EVAL_EXTRA_ARGS+=(--use-all)
fi

echo "Run configuration:"
echo "  RUN_CHECKLIST=$RUN_CHECKLIST"
echo "  RUN_SBAR=$RUN_SBAR"
echo "  RUN_UNCERTAIN=$RUN_UNCERTAIN"
echo "  RUN_TRAIN=$RUN_TRAIN"
echo "  CHECKLIST_OPTIMISER=$CHECKLIST_OPTIMISER"
echo "  SBAR_OPTIMISER=$SBAR_OPTIMISER"
echo "  UNCERTAIN_OPTIMISER=$UNCERTAIN_OPTIMISER"
echo "  UNCERTAIN_SIGNATURE_MODE=$UNCERTAIN_SIGNATURE_MODE"
echo "  UNCERTAIN_ANNOTATOR_ID=${UNCERTAIN_ANNOTATOR_ID:-<inherit ANNOTATOR_ID>}"
echo "  UNCERTAIN_EVAL_SPLIT=$UNCERTAIN_EVAL_SPLIT"
echo "  ANNOTATOR_ID=${ANNOTATOR_ID:-<all>}"
echo "  USE_ALL=$USE_ALL"
echo "  EVAL_MAX_RETRIES=$EVAL_MAX_RETRIES"
echo "  EVAL_RETRY_DELAY_SECONDS=$EVAL_RETRY_DELAY_SECONDS"
echo "  GPU_MONITOR_ENABLED=$GPU_MONITOR_ENABLED"
echo "  GPU_MONITOR_INTERVAL_SECONDS=$GPU_MONITOR_INTERVAL_SECONDS"

if [ "$RUN_TRAIN" = "1" ]; then
  NEED_REFLECTION=0
  if [[ "$CHECKLIST_OPTIMISER" == gepa_* ]] && [ "$RUN_CHECKLIST" = "1" ]; then
    NEED_REFLECTION=1
  fi
  if [[ "$SBAR_OPTIMISER" == gepa_* ]] && [ "$RUN_SBAR" = "1" ]; then
    NEED_REFLECTION=1
  fi
  if [[ "$UNCERTAIN_OPTIMISER" == gepa_* ]] && [ "$RUN_UNCERTAIN" = "1" ]; then
    NEED_REFLECTION=1
  fi

  if [ "$NEED_REFLECTION" = "1" ]; then
    if [ -z "${OPENAI_API_KEY:-}" ]; then
      echo "OPENAI_API_KEY is required for GEPA reflection (reflection model: $REFLECTION_MODEL)."
      exit 1
    fi
    echo "GEPA reflection model: $REFLECTION_MODEL"
  fi
fi

if [ "$RUN_CHECKLIST" = "1" ]; then
  CHECKLIST_MODEL_FILE="$OUT_DIR/compiled_programs/checklist_${MODEL_NAME}_${CHECKLIST_OPTIMISER}.json"
  CHECKLIST_EVAL_FILE="$OUT_DIR/evals/eval_checklist_${MODEL_NAME}_${CHECKLIST_OPTIMISER}.jsonl"
  CHECKLIST_GEPA_LOG_DIR="$OUT_DIR/gepa/checklist_${MODEL_NAME}_${CHECKLIST_OPTIMISER}"

  echo "=== CHECKLIST TASK ==="
  if [ "$RUN_TRAIN" = "1" ]; then
    if [ -s "$CHECKLIST_MODEL_FILE" ]; then
      echo "Checklist model exists, skipping training: $CHECKLIST_MODEL_FILE"
    else
      mkdir -p "$CHECKLIST_GEPA_LOG_DIR"
      "${PY_RUNNER[@]}" run_train_checklist.py \
        "${COMMON_ARGS[@]}" \
        --optimiser-name "$CHECKLIST_OPTIMISER" \
        --output-model-file "$CHECKLIST_MODEL_FILE" \
        --gepa-log-dir "$CHECKLIST_GEPA_LOG_DIR"
    fi

    if [ -s "$CHECKLIST_EVAL_FILE" ]; then
      echo "Checklist eval exists, skipping evaluation: $CHECKLIST_EVAL_FILE"
    else
      "${PY_RUNNER[@]}" run_eval_checklist.py \
        "${COMMON_ARGS[@]}" \
        --output-model-file "$CHECKLIST_MODEL_FILE" \
        --eval-results-file "$CHECKLIST_EVAL_FILE" \
        --max-retries "$EVAL_MAX_RETRIES" \
        --retry-delay-seconds "$EVAL_RETRY_DELAY_SECONDS" \
        "${EVAL_EXTRA_ARGS[@]}"
    fi
  else
    if [ -s "$CHECKLIST_EVAL_FILE" ]; then
      echo "Checklist baseline eval exists, skipping evaluation: $CHECKLIST_EVAL_FILE"
    else
      "${PY_RUNNER[@]}" run_eval_checklist.py \
        "${COMMON_ARGS[@]}" \
        --baseline \
        --eval-results-file "$CHECKLIST_EVAL_FILE" \
        --max-retries "$EVAL_MAX_RETRIES" \
        --retry-delay-seconds "$EVAL_RETRY_DELAY_SECONDS" \
        "${EVAL_EXTRA_ARGS[@]}"
    fi
  fi
fi

if [ "$RUN_SBAR" = "1" ]; then
  SBAR_MODEL_FILE="$OUT_DIR/compiled_programs/sbar_${MODEL_NAME}_${SBAR_OPTIMISER}.json"
  SBAR_EVAL_FILE="$OUT_DIR/evals/eval_sbar_${MODEL_NAME}_${SBAR_OPTIMISER}.jsonl"
  SBAR_GEPA_LOG_DIR="$OUT_DIR/gepa/sbar_${MODEL_NAME}_${SBAR_OPTIMISER}"

  echo "=== SBAR SPAN TASK ==="
  if [ "$RUN_TRAIN" = "1" ]; then
    if [ -s "$SBAR_MODEL_FILE" ]; then
      echo "SBAR model exists, skipping training: $SBAR_MODEL_FILE"
    else
      mkdir -p "$SBAR_GEPA_LOG_DIR"
      "${PY_RUNNER[@]}" run_train_sbar_span.py \
        "${COMMON_ARGS[@]}" \
        --optimiser-name "$SBAR_OPTIMISER" \
        --output-model-file "$SBAR_MODEL_FILE" \
        --gepa-log-dir "$SBAR_GEPA_LOG_DIR"
    fi

    if [ -s "$SBAR_EVAL_FILE" ]; then
      echo "SBAR eval exists, skipping evaluation: $SBAR_EVAL_FILE"
    else
      "${PY_RUNNER[@]}" run_eval_sbar_span.py \
        "${COMMON_ARGS[@]}" \
        --output-model-file "$SBAR_MODEL_FILE" \
        --eval-results-file "$SBAR_EVAL_FILE" \
        --max-retries "$EVAL_MAX_RETRIES" \
        --retry-delay-seconds "$EVAL_RETRY_DELAY_SECONDS" \
        "${EVAL_EXTRA_ARGS[@]}"
    fi
  else
    if [ -s "$SBAR_EVAL_FILE" ]; then
      echo "SBAR baseline eval exists, skipping evaluation: $SBAR_EVAL_FILE"
    else
      "${PY_RUNNER[@]}" run_eval_sbar_span.py \
        "${COMMON_ARGS[@]}" \
        --baseline \
        --eval-results-file "$SBAR_EVAL_FILE" \
        --max-retries "$EVAL_MAX_RETRIES" \
        --retry-delay-seconds "$EVAL_RETRY_DELAY_SECONDS" \
        "${EVAL_EXTRA_ARGS[@]}"
    fi
  fi
fi

if [ "$RUN_UNCERTAIN" = "1" ]; then
  UNCERTAIN_ARGS=("${COMMON_ARGS[@]}")
  if [ -n "$UNCERTAIN_ANNOTATOR_ID" ]; then
    UNCERTAIN_ARGS+=(--annotator-id "$UNCERTAIN_ANNOTATOR_ID")
  fi

  UNCERTAIN_MODEL_FILE="$OUT_DIR/compiled_programs/uncertain_${MODEL_NAME}_${UNCERTAIN_OPTIMISER}.json"
  UNCERTAIN_EVAL_FILE="$OUT_DIR/evals/eval_uncertain_${MODEL_NAME}_${UNCERTAIN_OPTIMISER}_${UNCERTAIN_ANNOTATOR_TAG}_${UNCERTAIN_EVAL_SPLIT}.jsonl"
  UNCERTAIN_GEPA_LOG_DIR="$OUT_DIR/gepa/uncertain_${MODEL_NAME}_${UNCERTAIN_OPTIMISER}"

  echo "=== UNCERTAIN SPAN TASK ==="
  if [ "$RUN_TRAIN" = "1" ]; then
    if [ -s "$UNCERTAIN_MODEL_FILE" ]; then
      echo "Uncertain model exists, skipping training: $UNCERTAIN_MODEL_FILE"
    else
      mkdir -p "$UNCERTAIN_GEPA_LOG_DIR"
      "${PY_RUNNER[@]}" run_train_uncertain_span.py \
        "${UNCERTAIN_ARGS[@]}" \
        --optimiser-name "$UNCERTAIN_OPTIMISER" \
        --output-model-file "$UNCERTAIN_MODEL_FILE" \
        --gepa-log-dir "$UNCERTAIN_GEPA_LOG_DIR"
    fi

    if [ -s "$UNCERTAIN_EVAL_FILE" ]; then
      echo "Uncertain eval exists, skipping evaluation: $UNCERTAIN_EVAL_FILE"
    else
      "${PY_RUNNER[@]}" run_eval_uncertain_span.py \
        "${UNCERTAIN_ARGS[@]}" \
        --output-model-file "$UNCERTAIN_MODEL_FILE" \
        --eval-results-file "$UNCERTAIN_EVAL_FILE" \
        --eval-split "$UNCERTAIN_EVAL_SPLIT"
    fi
  else
    if [ -s "$UNCERTAIN_EVAL_FILE" ]; then
      echo "Uncertain baseline eval exists, skipping evaluation: $UNCERTAIN_EVAL_FILE"
    else
      "${PY_RUNNER[@]}" run_eval_uncertain_span.py \
        "${UNCERTAIN_ARGS[@]}" \
        --baseline \
        --eval-results-file "$UNCERTAIN_EVAL_FILE" \
        --eval-split "$UNCERTAIN_EVAL_SPLIT"
    fi
  fi
fi

echo "All requested experiments completed."
echo "Artifacts:"
echo "  Models: $OUT_DIR/compiled_programs"
echo "  Evals:  $OUT_DIR/evals"
echo "  Logs:   $OUT_DIR/logs/job.log"
